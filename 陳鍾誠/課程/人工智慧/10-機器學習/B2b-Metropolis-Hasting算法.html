<!DOCTYPE html>
  <html>
  <head>
  <meta charset="UTF-8">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.2/katex.min.css">
  <link rel="stylesheet" type="text/css" href="https://ccc-js.github.io/pp6/doc/main.css">
  <!-- 
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/styles/atom-one-light.min.css">
  <link rel="stylesheet" type="text/css" href="file:///D:/ccc/js/pp6/doc/main.css"> 
  -->
  </head>
  <body>
  <title></title>
  <header>
    <div style="float:left"><label class="toggle" onclick="toggleSidebar()">≡</label>&nbsp;&nbsp;</div>
    <div style="float:left"><p><a href="../../../../陳鍾誠.html" alt="">陳鍾誠</a> / <a href="../../../課程.html" alt="">課程</a> / <a href="../../人工智慧.html" alt="">人工智慧</a> / <a href="../10-機器學習.html" alt="">10-機器學習</a></p>
</div>
  </header>
  <aside>
  <div>
  <h2> 人工智慧</h2>
<ul>
    <li><a href="01-人工智慧簡介.html" alt="">01-人工智慧簡介</a></li>
    <li><a href="02-爬山演算法.html" alt="">02-爬山演算法</a></li>
    <li><a href="03-神經網路.html" alt="">03-神經網路</a></li>
    <li><a href="04-圖形搜尋.html" alt="">04-圖形搜尋</a></li>
    <li><a href="05-電腦下棋.html" alt="">05-電腦下棋</a></li>
    <li><a href="06-邏輯推論.html" alt="">06-邏輯推論</a></li>
    <li><a href="07-語言處理.html" alt="">07-語言處理</a></li>
    <li><a href="08-科學計算.html" alt="">08-科學計算</a></li>
    <li><a href="09-模式識別.html" alt="">09-模式識別</a></li>
    <li><a href="10-機器學習.html" alt="">10-機器學習</a></li>
    <li><a href="11-深度學習.html" alt="">11-深度學習</a></li>
</ul>
<h2> 附錄</h2>
<ul>
    <li><a href="數學與程式.html" alt="">數學與程式</a></li>
    <li><a href="科學史.html" alt="">科學史</a></li>
    <li><a href="數學史.html" alt="">數學史</a></li>
    <li><a href="十分鐘系列.html" alt="">十分鐘系列投影片</a></li>
</ul>
  </div>
  </aside>
  <article>
  <div class="header">
    
    
    
  </div>
  <h2> Metropolis-Hasting 演算法</h2>

<p>「Metropolis-Hasting 演算法」(以下簡稱 MH 算法) 的設計，是建構在「馬可夫系統的細緻平衡條件」之上的，因此在說明「MH 算法」之前，必須先理解上述的「細緻平衡條件」，也就是對於圖中的每一條連線都必須達到「流入=流出」的均衡狀態。換句話說，就是符合下列條件。</p>

<p><span class="math display">
P(x) Q(x  \to  y) = P(y) Q(y  \to  x)
</span></p>

<p>Metropolis-Hasting 演算法 (MH 程序) 是一個不斷調整 Q(x→y) 的演算法，該算法所關注的焦點在於 (x, y) 通道上。</p>

<p>假如目前 x 的機率過高，而且從 x 流向 y 的粒子較多，那麼就應當讓粒子全部從 x 流向 y，也就是 Q(x→y) 的流量均可順利流出。但是如果從 y 流向 x 的粒子較多時，那麼我們就讓某些粒子卡住，不要流入 x。</p>

<p>但是究竟要流出多少粒子，卡住多少粒子呢？MH 方法利用下列的 A(x→y) 比例進行調節，以便能透過堵塞通道 Q(y→x) 的方法，讓系統趨向平衡。</p>

<p><span class="math display">
A(x \to y) = \frac{P(x) Q(x \to y)}{P(y) Q(y \to x)}
</span></p>

<p>因此，Metropolis 設計出了下列通道流量的調整公式，以便用疊代的方式調整狀態轉移機率矩陣 P(x \to y)。</p>

<p><span class="math display">
Q_{t+1}(x \to y) = \begin{cases} Q_t(x \to y) & \;\;\; \text{if x} \neq y  , A(x \to y) \geq 1;\\Q_t(x \to y) A(x \to y) & \;\;\;\text{if x} \neq y , A(x \to y) < 1;\\ Q_t(x \to y) + \sum_{z:A(x \to z) < 1} Q_t(x \to z) (1 - A(x \to z)) & \;\;\;\text{if x = y.} \end{cases}
</span></p>

<h3> Metropolis-Hasting 算法</h3>

<p>在理解了平衡條件與 MH 程序的想法後，我們就可以正式撰寫出 Metropolis-Hasting 程序的演算法。</p>

<pre class="code"><code class="">Algorithm Metropolis-Hasting(P(S)) output Q(S→S)
  foreach (x,y) in (S, S)
    Q(x→y) = 1/|S|
　while not converge
　　　foreach (x,y) in (S, S) // 計算 A 矩陣
　　　　　A(x→y) = (P(y) Q(y→x)) / (P(x) Q(x→y))

　　　foreach (x,y) in (S, S) // 計算下一代的轉移矩陣 Q
　　　　　if x = y
　　　　　　　Q'(x→y) = Q(x→y) + \sum_{z:A(x \to z) &lt; 1} Q_t(x \to z) (1 - A(x \to z))
　　　　　else
　　　　　　　if A(x→y) &gt;= 1
　　　　　　　　Q'(x→y) = Q(x→y)
　　　　　　　else
　　　　　　　　Q'(x→y) = Q(x→y) A(x→y)
　　　Q = Q'
　end while
End Algorithm
</code></pre>

<h3> MH 算法的進一步簡化</h3>

<p>在上述的 MH 程序中，算式 <code>\sum_{z:A(x \to z) &lt; 1} Q_t(x \to z) (1 - A(x \to z))</code> 是 <span class="math inline">\sum_{z:A(x \to z) < 1} Q_t(x \to z) (1 - A(x \to z))</span> 的 tex 數學式，該式的計算較為複雜，事實上，這個值就是為了讓 <span class="math inline">Q(x \to y)</span> 能夠『歸一化』的條件，也就是讓 <span class="math inline">\sum_y Q(x \to y)=1</span> 的差額補償值。因此我們也可以將上述演算法改寫如下。</p>

<pre class="code"><code class="">Algorithm Metropolis-Hasting(P(S)) output Q(S,S)
  foreach (x,y) in (S, S)
    Q(x→y) = 1/|S|
　while not converge
　　　foreach (x,y) in (S, S) // 計算 A 矩陣
　　　　　Q'(x→y) = Q(x→y)
　　　　　A(x→y) = (P(y) Q(y→x)) / (P(x) Q(x→y))

　　　foreach (x,y) in (S, S) // 計算下一代的轉移矩陣 Q
　　　　　if A(x,y) &lt; 1
　　　　　　　Q'(x→y) = Q(x→y) A(x→y)
　　　　　　　Q'(x→x) = Q(x→x) + Q(x→y) (1-A(x→y))

　　　Q = Q';
　end while
End Algorithm
</code></pre>

<h3> MH 算法的程式範例</h3>

<p>檔案：metropolis.js</p>

<pre class="code"><code class="javascript">// Metropolis Hasting 的範例
// 問題：機率式有限狀態機，P(s0)=0.3, P(s1)=0.5
// 目標：尋找「轉移矩陣」的穩態，也就是 Q(x→y)=? 時系統會達到平衡。

function rand(a, b) {
  return (b-a)*Math.random() + a;
}

function MetropolisHasting() {
  var P = [ 5.0/8, 3.0/8 ]; // 初始機率分佈，隨意設定。
  var Q = [ [0.5, 0.5], [0.5, 0.5] ]; // 初始機率分佈，隨意設定。
  var A = [ [0, 0], [0, 0]];
  do {
    console.log("Q = %j", Q);
    var Qn= [ [0,0], [0,0]];
    for (var x in Q) // 計算 A 矩陣
      for (var y in Q[x]) {
        Qn[x][y] = Q[x][y];
        A[x][y] = (P[y]*Q[y][x]) / (P[x]*Q[x][y]); // 入出比 = 流入/流出
      }
    
    console.log("A = %j", A);
    var diff = 0;
    for (var x in Q) 
      for (var y in Q[x]) { // 計算下一代 Qn 矩陣
        if (A[x][y] &lt; 1) {  // 入出比 &lt; 1 ，代表流入太少，流出太多
          Qn[x][y] = Q[x][y] * A[x][y]; // 降低流出量
          Qn[x][x] = Qn[x][x]+Q[x][y]*(1-A[x][y]); // 『規一化』調整
          diff += Math.abs(Qn[x][y]-Q[x][y]); // 計算新舊矩陣差異
        }
      }
    Q = Qn;
    console.log("diff = %d", diff);
  } while (diff &gt; 0.001);  // 假如差異夠小的時候，就可以停止了。
}

MetropolisHasting();
</code></pre>

<p>執行結果</p>

<pre class="code"><code class="">D:\Dropbox\Public\web\ml\code\Gibbs&gt;node metropolis.js
Q = [[0.5,0.5],[0.5,0.5]]
A = [[1,0.6],[1.6666666666666667,1]]
diff = 0.2
Q = [[0.7,0.3],[0.5,0.5]]
A = [[1,1],[1,1]]
diff = 0
</code></pre>

<p>Metropolis-Hasting 程序可以用來學習具有『細緻平衡』特性的狀態轉移機率 Q(x→y)，一但取得了狀態轉移機率，整個系統的機率行為就確定下來了，透過這樣的程序，我們可以學習到一個馬可夫模型，然後再利用這個模型進行『預測』，以便讓程式的行為模擬該馬可夫系統的行為。Metropolis-Hasting 程序對這些可用隨機系統描述的行為而言，是一個重要的學習程序，因此被廣泛應用在機器翻譯、文件分類、分群或貝氏網路的學習等領域上，這是數學領域在電腦上應用的一個優良方法。</p>

<h3> 結語</h3>

<p>在本章中我們看到了兩種「馬可夫模型」的學習方法，Gibbs Algorithm 可以在已知「狀態轉移矩陣」 P(x→y) 的情況下，學習每個狀態的機率 P(x)。</p>

<p>而 Metropolis-Hasting 程序則可以在已知每個狀態的機率 P(x) 的情況下，學習「狀態轉移矩陣」 P(x→y) 的機率值。</p>

<p>當然、這是在沒有隱變數情況下的學習，如果有隱變數的時候，我們就必須採用「隱馬可夫模型」的學習方法才行。</p>

  <div class="reference">
  
  </div>
  </article>
  <footer><p><a href="http://www.nqu.edu.tw/educsie/index.php?act=blog&code=list&ids=4" alt="">陳鍾誠</a> 於 <a href="http://www.nqu.edu.tw/" alt="">金門大學</a> <a href="http://www.nqu.edu.tw/educsie/index.php" alt="">資訊工程系</a> -- 本書衍生自 <a href="https://www.wikipedia.org/" alt="">維基百科</a> ，採用 <a href="https://zh.wikipedia.org/zh-hant/Wikipedia%3ACC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" alt="">CC: BY-SA</a> 授權</p>
</footer>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.2/katex.min.js"></script>
  <script src="https://ccc-js.github.io/pp6/doc/main.js"></script>
  <!--
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/highlight.min.js"></script>
  <script src="file:///D:/ccc/js/pp6/doc/main.js"></script>
  -->
  </script>
  </body>
  </html>
  